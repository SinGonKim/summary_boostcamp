## Lecture3: 좋은 모델과 파라미터 찾기: AutoML 이론

### 1. Overview

So called "Data Engineering"

- Data Cleansing, Preprocessing
- Feature Engineering
- Select ML Algorithm
  - 특히 Deep Learning에서는 Select Backbone Model(ResNet, MobileNet, EfficientNet,...)
- Set Hyperparameters
  - Hyperparameters(Loss, Optimizer, Learning rate, Batchsize, ...)
- ...

![a1](https://user-images.githubusercontent.com/87477828/143424415-960b1905-a2c4-4eb0-a9a6-54a3fb3107b0.png)

반복적인(Human in the Loop) Tuning 과정

![a1](https://user-images.githubusercontent.com/87477828/143424705-130d3ff5-0ddc-48ed-a964-e3c0c6505553.png)

![a2](https://user-images.githubusercontent.com/87477828/143424714-85abbb56-6292-4bbf-9071-370ca99988a4.png)

AutoML: "True" End-to-end learning

![a1](https://user-images.githubusercontent.com/87477828/143425525-4ae8acb1-5376-407a-8b97-09f963cbd188.png)

AutoML(HPO: Hyperparameter Optimization)의 문제 정의

![a1](https://user-images.githubusercontent.com/87477828/143425781-a6f0d667-e1f4-4695-9b85-0873752aa1ce.png)

DL model Configuration(Architecture, Hyperparameter)의 특징

1. 주요 타입 구분

   A. Categorical

    - ex) optimizer: [Adam, SGD, AdamW, ...], module: [Conv, BottleNeck, InvertedResidual, ...]

​		B. Continuous

​			- ex) learning rate, regularizer param, ...

​		C. Integer

​			- ex) batch_size, epochs, ...

  2. Conditional:한 configuration에 따라 search space가 달라질 수 있음

     A. Optimizer의 Sample(e.g. SGDm Adam 등등)에 따라서 optimizer parameter의 종류, search space도 달라짐 (e.g. optimizer에 따른 learning ate range 차이, SGD: momentum, Adam: alpha, beta1, beta2, .. 등등)

     B. Module의 Sample(e.g. Vanilla Conv, BottleNeck, InvertedResidual 등등)에 따라서 해당 module의 parameter의 종류, search space도 달라짐



#### (주어진)모델을 경량화하자 vs (새로운)경량 모델을 찾자

- 모델경량화의 접근 두가지
- 기존 가지고 있는 모델을 경량화 하는 기법
  - Pruning, Tensor, decomposition, ...

- Search를 통하여 경량 모델을 찾는 기법
  - NAS(Neural Architecture Search) , AutoML(Automated Machine Learning),...

### 2. Basic Concept

#### 일반적인 AutoML Pipeline

![a1](https://user-images.githubusercontent.com/87477828/143427340-c230d179-26be-4236-8d22-4e979615a17f.png)



AutoML Pipeline 예시 : Bayesian Optimization(B0)

![a1](https://user-images.githubusercontent.com/87477828/143427468-b7dced7f-8b51-4858-b69c-68a7babb5882.png)

![a1](https://user-images.githubusercontent.com/87477828/143427701-954dfb73-7d60-405f-a0db-04a121fc4fc9.png)

매 iteration 마다,

1. 람다를 Sample(obervation)

2. 해당 Sample(configuration)로 DL 모델을 학습,

3. objective를 계산(우측 point)

4. Surrogate model 업데이트

   (그림의 실선, 파란 영역) (ex: GP model, posterior mean, posterior variance(uncertainty))

5. Acquistion function 업데이트

   (그림의 초록 영역), (ex: Expected imporvement, Upper Confidence Bounds)



- Gaussian Process Regression
  - 알아서 공부



- Surrogate Model(Function): Regression model
  - Objective f 값을 예측 하는 모델
  - Objective를 estimate하는 surrogate model을 학습, 다음 좋은 람다를 선택하는 기준으로 사용
  - 대표적인 Surrogate model로는 Gaussian Process Regression(GPR) Model (Mean: 예측 f값, Var: uncertainty)

- Acquistion Function: 다음은 어디를 trial하면 좋을까?
  - Surrogate model의 output으로부터, 다음 시도해보면 좋을 람다를 계산하는 함수
  - Exploration vs Exploitation ("불확실한 지점 vs 알고있는 가장 좋은 곳")
  - Acquistion function의 max 지점을 다음 iteration에서 trial
  - Ex) Upper Confidence Bound(UCB)
    - ![a1](https://user-images.githubusercontent.com/87477828/143428774-924ec7c1-c9f7-4495-aaca-177c153f675e.png)

