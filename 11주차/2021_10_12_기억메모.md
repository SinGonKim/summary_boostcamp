## Lecture1: MRC Intro& Python Basics

### 1. introduction to MRC

- MRC의 개념

  ```markdown
  ### 기계 독해 (Machine Reading Comprehension) 이란?
  : 주어진 지문(context)를 이해하고, 주어진 질의(Query/Questoin)의 답변을 추론하는 문제
  ```

  ![](https://user-images.githubusercontent.com/87477828/136885985-22ebf20e-cfa9-40b7-92e7-338bee4bcd01.png)

  ![기계독해 개념2](https://user-images.githubusercontent.com/87477828/136885992-547804d6-cbb8-48c7-a228-51fb2d5be9c8.png)

- MRC의 종류

  - Extractive Answer Datasets : 질의 (Question)에 대한 답이 항상 **주어진 지문(context)**의 segment(or span)으로 존재

    ![Extractive Answer Datasets](https://user-images.githubusercontent.com/87477828/136887032-af863cbf-2cc2-4c40-bb4d-45d977cd3b12.png)

  - Descriptive/Narrative Answer Datasets : 답이 지문 내에서 추출한 span이 아니라, 질의를 보고 생성 된 sentence (or free-from(자유로운 form))의 형태

    ![Descriptive Narrative Answer Datasets](https://user-images.githubusercontent.com/87477828/136887030-123b5de6-19ec-4275-a21c-5d2872b274d3.png)

  - Multiple-choice Datasets : 질의에 대한 답을 여러 개의 answer candidates 중 하나로 고르는 형태

    ![MCT Datasets](https://user-images.githubusercontent.com/87477828/136887034-305da3f7-3fce-413a-89f1-ca07f2f4ee36.png)

- MRC Datasets
  - MRC 기본 : 주어진 지문에 대한 질문 답변
  - MRC 응용 : 지문이 주어지지 않아도 질문에 대해 웹을 통해 답변을 가져옴

- Challenges in MRC

  - 단어들의 구성이 유사하지는 않지만 동일한 의미의 문장을 이해

  - Dataset example : DuoRC (paraphrased paragraph)/ QuoRef (coreference resolution)

    ![1](https://user-images.githubusercontent.com/87477828/136887583-63c6ead9-6add-4a39-99f3-59fe928d85ce.png)

  - Unanswerable question(답변을 할 수 없는 질문)

    - Question with 'No Answer'

    - ex. SQuAD 2.0

      ![1](https://user-images.githubusercontent.com/87477828/136887739-a47b5ecd-710c-4a14-9779-fdc0834e2173.png)

       - Example : little opposition(paragraph) vs significant opposition(question)

         -> 주어진 지문에서는 질문에 대한 답을 찾을 수 없음. (즉 later laws는 주어진 질문에 오답임)

  - Multi-hop reasoning

    - 여러 개의 document에서 질의에 대한 supporting fact를 찾아야지만 답을 찾을 수 있음

      - Ex) HotpotQA, QAngaroo

        ![1](https://user-images.githubusercontent.com/87477828/136888169-654ed89e-f375-448e-9696-ce7cfa7892be.png)

- MRC 평가 방법

  - Extract Match/F1 Score : For extractive answer and multiple-choice answer datasets

    - `Extract Match (EM)` or `Accuracy`
      - 예측한 답과 ground-truth이 정확히 일치하는 샘플의 비율 (Number of correct samples)/(Number of whole samples)

    - `F1 Score`
      - 예측한 답과 ground-truth 사이의 token overlap을 F1으로 계산

    ![1](https://user-images.githubusercontent.com/87477828/136888443-151be21f-172f-4a71-8060-e7e94e4627bd.png)

  - ROUGE-L/ BLEU : For descriptive answer datasets

    - Ground-truth과 예측한 답 사이의 overlap을 계산

    - `ROUGE-L-Score`

      - 예측한 값과 ground-truth 사이의 overlap recall

        ROUGE-L -> LCS(Longest common subsequence)기반

    - `BLEU` (Bilingual Evaluation Understudy)

      - 예측한 답과 ground-truth 사이의 precision

        (BLEU-n => uniform n-gram weight)



### 2. Unicode & Tokenization

```markdown
### Unicode란?
전 세계의 모든 문자를 일관되게 표현하고 다룰 수 있도록 만들어진 문자셋
각 문자마다 숫자 하나에 매핑한다.
```

![1](https://user-images.githubusercontent.com/87477828/136889106-b06899ab-c38b-402d-b920-14c31b19ceaf.png)

- 인코딩 & UTF-8

  ```markdown
  ### 인코딩이란?
   문자를 컴퓨터에서 저장 및 처리할 수 있게 이진수로 바꾸는 것
  ### UTF-8(Unicode Transformation Format)
   UTF-8는 현재 가장 많이 쓰는 인코딩 방식
   문자 타입에 따라 다른 길이의 바이트를 할당한다.
   	1byte: Standard ASCII
   	2byes: Arabic, Hebrew, most European scripts
   	3byes: BMP(Basic Multilingual Plane)- 대부분의 현대 글자(한글 포함)
   	4byes: All Unicode characters - 이모지 등
  ```

- Python에서 Unicode 다루기

  - Python3부터 string타입은 유니코드 표준을 사용한다.

    - ord : 문자를 유니코드 code point로 변환한다.

    - chr : Code point를 문자로 변환한다.

      ![1](https://user-images.githubusercontent.com/87477828/136889790-052961ca-e6f8-42d7-92c1-a7bae1951805.png)

- Unicode와 한국어

  - 한국어는 한자 다음으로 유니코드에서 많은 코드를 차지하고 있는 문자이다.

    - 완성형

      현대 한국어의 자모 조합으로 나타낼 수 있는 모든 완성형 한글 11,172자(가, 각 ...)

      (U+AC00~ U+D7A3)

    - 조합형

      조합하여 글자를 만들 수 있는 초,중,종성

      (U+1100~U+``FF, U+A960~U+A97F, U+D7B0~U+D7FF)

```markdown
### 토크나이징이란?
 텍스트를 토큰 단위로 나누는 것
 단어(띄어쓰기 기준), 형태소, subwod등 여러 토큰 기준이 사용된다.
 
### Subword 토크나이징
 자주 쓰이는 글자 조합은 한 단위로 취급하고, 자주 쓰이지 않는 조합은 subword로 쪼갠다.
 '##'은 디코딛 (토크나이징의 반대과정)을 할 때 해당 토큰을 앞 토큰에 띄어쓰기 없이 붙인다는 것을 뜻한다.
```

![1](https://user-images.githubusercontent.com/87477828/136890258-5a09c163-0749-4794-8b40-60a728c647de.png)

- BPE(Byte-Pair-Encoding)
  - 데이터 압축용으로 제안된 알고리즘으로 NLP에서 토크나이징용으로 활발하게 사용되고 있다.
    1. 가장 자주 나오는 글자 단위 Bigram (or Byte pair)를 다른 글자로 치환한다.
    2. 치환된 글자를 저장해둔다.
    3. 1~2번을 반복한다.

### Looking into the Dataset

```markdown
### KorQuAD란?
LG CNS가 AI 언어지능 연구를 위해 공개한 질의응답/기계독해 한국어 데이터셋 인공지능이 한국어 질문에 대한 답변을 하도록 필요한 학습 데이터셋
```

![1](https://user-images.githubusercontent.com/87477828/136890788-5a9c8033-6352-4fec-8ceb-8b2dec0742f7.png)



- KorQuAD 데이터 수집 과정
  - SQuAD v1.0의 데이터 수집 방식을 벤치마크하여 표준성을 확보함

![1](https://user-images.githubusercontent.com/87477828/136890914-d008365b-9d74-455b-a05e-b0c885673b67.png)

- HuggingFace Datasets 라이브러리

  - Numpy, Pandas, Pytorch, Tensorflow2와 호환

  - 접근가능한 모든 데이터셋이 memory-mapped, cached 되어있어 데이터를 로드 하면서 생기는 메모리 공간 부족이나 전처리 과정 반복의 번거로움을 피할 수 있음

  - KorQuAD 데이터셋의 경우 squad_kor_v1, squad_kor_v2 로 불러올 수 있음

    ```python
    from datasets import load_dataset
    dataset = load_dataset('squad_kor_v1', split= 'train')
    ```

    [hugging_face_Datasets](https://huggingface.co/docs/datasets/)

    [hugging_face_KorQuAD](https://huggingface.co/datasets?search=kor)

    

 ![1](https://user-images.githubusercontent.com/87477828/136891839-e7c6fee6-8eb9-4095-92f4-4c8cf86c3ef3.png)
![2](https://user-images.githubusercontent.com/87477828/136891841-6c0a8b94-718d-4057-95bd-229082377c63.png)
![3](https://user-images.githubusercontent.com/87477828/136891842-d2ed64af-bc0c-476e-9f52-a84b4384162a.png)
![4](https://user-images.githubusercontent.com/87477828/136891843-3a54406d-7bfd-4d34-b56c-bb126f515b1d.png)

​	-  원인, 방법등은 상당히 까다로운 유형임.

```markdown
### Reference
- https://www.slideshare.net/SeungyoungLim/korquad-introduction:KorQuADintroduction(LGCNS)
- NeuralMachineReadingComprehension:MethodsandTrends(Liuetal.,AppliedScience,2019)
- MSMARCO:AHumanGeneratedMAchineReadingCOmprehensionDataset(Bajajetal.NIPS2016)
- MCTest:AChallengeDatasetfortheOpen-DomainMachineComprehensionofText (Richardson,EMNLP2013)
- KnowWhatYouDon’tKnow:UnanswerableQuestionsforSQuAD(Rajpurkaretal.,ACL2018)
- HOTPOTQA:ADatasetforDiverse,ExplainableMulti-hopQuestionAnswering(Yangetal.,EMNLP2018)
- Multi-hopQuestionAnsweringviaReasoningChains(Chenetal.,2019)
- https://paperswithcode.com/sota/question-answering-on-narrativeqa
- DuoRC:TowardsComplexLanguageUnderstandingwithParaphrasedReadingComprehension(Sahaetal.,ACl2018)
- KorQuAD2.0:웹문서 기계독해를 위한 한국어 질의응답 데이터셋 (Kimetal.,2019)
- 한국어 MRC연구를 위한 표준 데이터셋(KorQuAD)소개 및 B2B를 위한 MRC연구 사례,https://tv.naver.com/v/5564630
- WhatEveryProgrammerAbsolutely,PositivelyNeedsToKnowAboutEncodingsAndCharacterSetsToWorkWithText,
https://kunststube.net/encoding/
- Bytepairencoding,https://en.wikipedia.org/wiki/Byte_pair_encoding
```

### 실습

```python
from datasets import load_dataset

dataset = load_dataset("squad_kor_v1")
```

가 서버에 연결한 vscode에서 안먹힐 때가 있다.

그럴 때

```python
pip install ipywidgets
```

를 하면 ipywidgets를  수 있어서 사용가능해진다고 한다.

conda에서 하면

```python
conda install -c conda-forge ipywidgets
```

[참고자료](https://ipywidgets.readthedocs.io/en/stable/user_install.html)



